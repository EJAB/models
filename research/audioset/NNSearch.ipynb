{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# displays the full results\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a numpy array of size 1*128, all zeros - this will be the first row in the resulting matrix\n",
    "index = np.zeros((1,128))\n",
    "np.save(r\"/Users/janelabumanglag/FYP/models/research/audioset/samples/index.npy\", index)\n",
    "\n",
    "# creates a txt file that contains all the names of the audio recordings\n",
    "filenames = np.array([\"\"], dtype=str)\n",
    "np.savetxt(r\"/Users/janelabumanglag/FYP/models/research/audioset/samples/filenames.txt\", filenames, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 128)\n"
     ]
    }
   ],
   "source": [
    "arr = np.load(r\"/Users/janelabumanglag/FYP/models/research/audioset/samples/index.npy\")\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n200\n(200, 128)\n"
     ]
    }
   ],
   "source": [
    "f = open(r\"/Users/janelabumanglag/FYP/models/research/audioset/samples/filenames.txt\", 'r')\n",
    "names = []\n",
    "for line in f:\n",
    "    # print(line, end='')\n",
    "    names.append(line)\n",
    "    \n",
    "print(len(names))\n",
    "del names[0]\n",
    "print(len(names))\n",
    "\n",
    "newArr = np.delete(arr, 0, 0)\n",
    "print(newArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 128)\nQuery file:  (1, 128)\n"
     ]
    }
   ],
   "source": [
    "query = np.load(\"/Users/janelabumanglag/FYP/models/research/audioset/short_applause.wav.npy\")\n",
    "print(query.shape)\n",
    "l2Query = preprocessing.normalize(query, norm='l2', axis=1)\n",
    "sumQuery = np.sum(l2Query, axis=0)\n",
    "newQuery = np.array(sumQuery)[None, :]\n",
    "finalQuery = preprocessing.normalize(newQuery, norm='l2', axis=1)\n",
    "print(\"Query file: \", finalQuery.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_positive = np.dot(newArr, finalQuery.T)\n",
    "print(\"Dot product: \", dot_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([66]), array([0]))\n<class 'numpy.ndarray'>\n[66, 10, 59, 7, 77]\n0HbhE91JB-k_360.000.wav\n\n00G2vNrTnCc_10.000.wav\n\n0Gxn9FtaJFc_30.000.wav\n\n0-yskgO46Bg_30.000.wav\n\n0J_TdiZ3TKA_30.000.wav\n\n"
     ]
    }
   ],
   "source": [
    "print(np.where(dot_positive >= np.max(dot_positive)))\n",
    "top5 = heapq.nlargest(5, range(len(dot_positive)), dot_positive.__getitem__)\n",
    "print(type(dot_positive))\n",
    "print(top5)\n",
    "for i in top5:\n",
    "    print(names[i])  # prints out 69, 13, 62, 10, 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
